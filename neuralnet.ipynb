{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.1' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "# Load the CSV data\n",
    "df = pd.read_csv('cleaned_output.csv')\n",
    "\n",
    "# Preprocessing - Flatten 'lo' column (list of tuples)\n",
    "# We'll convert 'lo' from string format to actual list of tuples\n",
    "def parse_lo(lo_str):\n",
    "    # Safely evaluate the stringified tuple list (this converts it to a list of tuples)\n",
    "    try:\n",
    "        lo_list = ast.literal_eval(lo_str)\n",
    "        return [tup[1] for tup in lo_list]  # We take the second element of each tuple\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing lo: {e}\")\n",
    "        return []\n",
    "\n",
    "df['lo'] = df['lo'].apply(parse_lo)\n",
    "\n",
    "# Now, we'll split 'lo' into separate columns for each tuple value\n",
    "lo_columns = ['lo_' + str(i) for i in range(df['lo'].apply(len).max())]  # Dynamically create columns for the lo list\n",
    "\n",
    "# Expand the 'lo' column into multiple columns\n",
    "df[lo_columns] = pd.DataFrame(df['lo'].to_list(), index=df.index)\n",
    "\n",
    "# Drop the original 'lo' column (since we now have separate columns)\n",
    "df.drop(columns=['lo'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "\n",
    "# Define features (X) and target (Y)\n",
    "X = df.drop(columns=['c_0', 'c_1', 'b_0', 'b_1', 'q_0', 'q_1'])\n",
    "y = df[['c_0', 'c_1', 'b_0', 'b_1', 'q_0', 'q_1']]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the data (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the Neural Network Model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Input Layer (taking all the features)\n",
    "model.add(layers.InputLayer(input_shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Hidden Layers (2 layers with 64 units and ReLU activation)\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Output Layer (6 values: c_0, c_1, b_0, b_1, q_0, q_1)\n",
    "model.add(layers.Dense(6))  # No activation because we are doing regression\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')  # MSE loss for regression tasks\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test Loss (MSE): {loss}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# You can now use `y_pred` to compare against `y_test` or save the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
